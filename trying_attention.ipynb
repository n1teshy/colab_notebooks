{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sbLzjf46yMyQ"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "D_MODEL = 100\n",
        "HEAD_SIZE = 10\n",
        "BLOCK_SIZE = 3\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "o_mCCKYcymNa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Head(nn.Module):\n",
        "  def __init__(self, head_size):\n",
        "    super().__init__()\n",
        "    self.key = nn.Linear(D_MODEL, head_size)\n",
        "    self.query = nn.Linear(D_MODEL, head_size)\n",
        "    self.value = nn.Linear(D_MODEL, head_size)\n",
        "\n",
        "  def forward(self, x):\n",
        "    k = self.key(x) # (BLK_SZ, D_MDL) @ (D_MDL, HD_SZ) ->  (BLK_SZ, HD_SZ)\n",
        "    q = self.query(x) # BLK_SZ, D_MDL) @ (D_MDL, HD_SZ) ->  (BLK_SZ, HD_SZ)\n",
        "    v = self.value(x) # BLK_SZ, D_MDL) @ (D_MDL, HD_SZ) ->  (BLK_SZ, HD_SZ)\n",
        "    attn = q @ k.T # (BLK_SZ, HD_SZ) @ (HD_SZ, BLK_SZ) -> (BLK_SZ, BLK_SZ)\n",
        "    value = attn @ v # (BLK_SZ, BLK_SZ) @ (D_MDL, HD_SZ) -> (BLK_SZ, HD_SZ)\n",
        "    return F.softmax(value, dim=-1)\n",
        "\n"
      ],
      "metadata": {
        "id": "OUT6SIxHySTz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MultiHead(nn.Module):\n",
        "  def __init__(self, head_size):\n",
        "    super().__init__()\n",
        "    assert D_MODEL % head_size == 0, \"D_MODEL must be divisible by head_size\"\n",
        "    num_heads = D_MODEL // head_size\n",
        "    self.heads = nn.ModuleList([Head(head_size) for _ in range(num_heads)])\n",
        "\n",
        "  def forward(self, x):\n",
        "    out = torch.cat([head(x) for head in self.heads], dim=-1)\n",
        "    return F.softmax(out, dim=-1)\n"
      ],
      "metadata": {
        "id": "zEFbtbGa3hSt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = torch.randn((BLOCK_SIZE, D_MODEL)).to(DEVICE)\n",
        "model = MultiHead(HEAD_SIZE).to(DEVICE)\n",
        "print(model(X).shape)"
      ],
      "metadata": {
        "id": "1M9BO7IA1J1u"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}